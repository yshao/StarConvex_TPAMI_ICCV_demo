{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c83f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f596b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from data import ModelNet40\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from torch import jit\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "import importlib\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pytorch3d\n",
    "import numpy as np\n",
    "import pytorch3d\n",
    "from pytorch3d.transforms import matrix_to_euler_angles\n",
    "from pytorch3d.transforms import euler_angles_to_matrix\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2cc30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e1faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,4,5,6,7'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,4,5,6,7'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46104efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee4d6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success utils\n",
      "model loaded success\n",
      "success model\n"
     ]
    }
   ],
   "source": [
    "# 1. Set the path to the demo through sys.path\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/workspace/ICCV_demo')\n",
    "\n",
    "\n",
    "# Learning3D model has been trimmed down to the PRNet for demo purpose\n",
    "from learning3d.models import PRNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b3a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def options():\n",
    "    parser = argparse.ArgumentParser(description='Point Cloud Registration')\n",
    "    parser.add_argument('--exp_name', type=str, default='exp', metavar='N',\n",
    "                        help='Name of the experiment')\n",
    "    parser.add_argument('--model', type=str, default='dcp', metavar='N',\n",
    "                        choices=['dcp'],\n",
    "                        help='Model to use, [dcp]')\n",
    "    parser.add_argument('--emb_nn', type=str, default='pointnet', metavar='N',\n",
    "                        choices=['pointnet', 'dgcnn'],\n",
    "                        help='Embedding nn to use, [pointnet, dgcnn]')\n",
    "    parser.add_argument('--pointer', type=str, default='transformer', metavar='N',\n",
    "                        choices=['identity', 'transformer'],\n",
    "                        help='Attention-based pointer generator to use, [identity, transformer]')\n",
    "    parser.add_argument('--head', type=str, default='svd', metavar='N',\n",
    "                        choices=['mlp', 'svd', ],\n",
    "                        help='Head to use, [mlp, svd]')\n",
    "    parser.add_argument('--emb_dims', type=int, default=512, metavar='N',\n",
    "                        help='Dimension of embeddings')\n",
    "    parser.add_argument('--n_blocks', type=int, default=1, metavar='N',\n",
    "                        help='Num of blocks of encoder&decoder')\n",
    "    parser.add_argument('--n_heads', type=int, default=4, metavar='N',\n",
    "                        help='Num of heads in multiheadedattention')\n",
    "    parser.add_argument('--ff_dims', type=int, default=1024, metavar='N',\n",
    "                        help='Num of dimensions of fc in transformer')\n",
    "    parser.add_argument('--dropout', type=float, default=0.0, metavar='N',\n",
    "                        help='Dropout ratio in transformer')\n",
    "    parser.add_argument('--batch_size', type=int, default=2, metavar='batch_size',\n",
    "                        help='Size of batch)')\n",
    "    parser.add_argument('--test_batch_size', type=int, default=1, metavar='batch_size',\n",
    "                        help='Size of batch)')\n",
    "    parser.add_argument('--epochs', type=int, default=100, metavar='N',\n",
    "                        help='number of episode to train ')\n",
    "    parser.add_argument('--use_sgd', action='store_true', default=False,\n",
    "                        help='Use SGD')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                        help='learning rate (default: 0.001, 0.1 if using sgd)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                        help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--no_cuda', action='store_true', default=False,\n",
    "                        help='enables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1234, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--eval', action='store_true', default=False,\n",
    "                        help='evaluate the model')\n",
    "    parser.add_argument('--cycle', type=bool, default=False, metavar='N',\n",
    "                        help='Whether to use cycle consistency')\n",
    "    parser.add_argument('--gaussian_noise', type=bool, default=False, metavar='N',\n",
    "                        help='Wheter to add gaussian noise')\n",
    "    parser.add_argument('--unseen', type=bool, default=False, metavar='N',\n",
    "                        help='Wheter to test on unseen category')\n",
    "    parser.add_argument('--num_points', type=int, default=1024, metavar='N',\n",
    "                        help='Num of points to use')\n",
    "    parser.add_argument('--dataset', type=str, default='modelnet40', choices=['modelnet40'], metavar='N',\n",
    "                        help='dataset to use')\n",
    "    parser.add_argument('--factor', type=float, default=4, metavar='N',\n",
    "                        help='Divided factor for rotations')\n",
    "    parser.add_argument('--model_path', type=str, default='', metavar='N',\n",
    "                        help='Pretrained model path')\n",
    "\n",
    "    args = parser.parse_args(\"\")\n",
    "    return args\n",
    "\n",
    "args = options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8047d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f8ba7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Net definition ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b3b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3824335",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Net Params ###\n",
    "args.pointer = 'transformer'\n",
    "args.num_iterations = 3\n",
    "\n",
    "args.emb_nn = 'dgcnn'\n",
    "args.lam = 0.3\n",
    "args.mu = 0.3\n",
    "args.emb_dims = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1844ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0')\n",
    "model = PRNet(emb_dims=args.emb_dims, num_iters=args.num_iterations, emb_nn=args.emb_nn, attention=args.pointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eaaac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_point_cloud(point_cloud, rotation, translation):\n",
    "    rot_mat = rotation\n",
    "    return torch.matmul(rot_mat, point_cloud) + translation.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb4596c5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e036dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_free():\n",
    "    #     del loss3\n",
    "    import torch\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc\n",
    "    return gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48a9116f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f768d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec6e1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap(factor=4):\n",
    "    \"\"\n",
    "    #     factor=4\n",
    "    anglex = np.random.uniform() * np.pi / factor\n",
    "    angley = np.random.uniform() * np.pi / factor\n",
    "    anglez = np.random.uniform() * np.pi / factor\n",
    "\n",
    "    cosx = np.cos(anglex)\n",
    "    cosy = np.cos(angley)\n",
    "    cosz = np.cos(anglez)\n",
    "    sinx = np.sin(anglex)\n",
    "    siny = np.sin(angley)\n",
    "    sinz = np.sin(anglez)\n",
    "    Rx = np.array([[1, 0, 0],\n",
    "                   [0, cosx, -sinx],\n",
    "                   [0, sinx, cosx]])\n",
    "    Ry = np.array([[cosy, 0, siny],\n",
    "                   [0, 1, 0],\n",
    "                   [-siny, 0, cosy]])\n",
    "    Rz = np.array([[cosz, -sinz, 0],\n",
    "                   [sinz, cosz, 0],\n",
    "                   [0, 0, 1]])\n",
    "    R_ab = Rx.dot(Ry).dot(Rz)\n",
    "\n",
    "    translation_ab = np.array([np.random.uniform(-0.5, 0.5), np.random.uniform(-0.5, 0.5),\n",
    "                               np.random.uniform(-0.5, 0.5)])\n",
    "\n",
    "    #     device=next(self.parameters()).device\n",
    "    R_ab_t = torch.from_numpy(R_ab).type(torch.FloatTensor).unsqueeze(0).to(device)\n",
    "    translation_ab_t = torch.from_numpy(translation_ab).type(torch.FloatTensor).unsqueeze(0).to(device)\n",
    "\n",
    "    return R_ab_t, translation_ab_t, [anglex, angley, anglez]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51730dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device=torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "495f823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "R, t, _ = get_bootstrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f888c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PRNet(emb_dims=args.emb_dims, num_iters=args.num_iterations, emb_nn=args.emb_nn, attention=args.pointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65898f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e08681db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5cd87d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Demo EVALUATION Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca537293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7609b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main evaluation function - W/O ICP refine\n",
    "def eval_rnn_with_weights_std_batches(wt=[1.0, 1.0, 1.0, 1.0], loop_iter=4, \n",
    "                                      data_loader=None, print_progress=True):\n",
    "    if len(wt) != loop_iter:\n",
    "        print('weights do not match')\n",
    "        return\n",
    "    # By default set to modelnet40\n",
    "    if (data_loader == None):\n",
    "        data_loader = rl_loader\n",
    "        print('modelnet40', rl_loader)\n",
    "    else:\n",
    "        print('otherwise', data_loader)\n",
    "        \n",
    "    print('EVALUATE length', len(data_loader.dataset))\n",
    "\n",
    "    print('params:')\n",
    "    print('loop',loop_iter)\n",
    "    \n",
    "    Unseen_test_loss_log = []\n",
    "\n",
    "    Unseen_test_L = []\n",
    "\n",
    "    Unseen_trans_L = []\n",
    "\n",
    "    Unseen_euler_L = []\n",
    "\n",
    "    Unseen_euler_abs_L = []\n",
    "\n",
    "    Unseen_t_L = []\n",
    "\n",
    "    net.eval()\n",
    "    Unseen_test_loss = 0\n",
    "    Unseen_trans_loss = 0\n",
    "    Unseen_euler_loss = 0\n",
    "    Unseen_euler_abs_loss = 0\n",
    "    correct_test = 0\n",
    "    \n",
    "    ### STD\n",
    "    Unseen_euler_loss_na = []\n",
    "    Unseen_r_mse_na = []\n",
    "    Unseen_t_mse_na = []\n",
    "\n",
    "    #### new metrics\n",
    "    Unseen_r_mse = 0.0\n",
    "    Unseen_r_rmse = 0.0\n",
    "    Unseen_r_mae = 0.0\n",
    "    Unseen_t_mse = 0.0\n",
    "    Unseen_t_rmse = 0.0\n",
    "    Unseen_t_mae = 0.0\n",
    "    \n",
    "    Unseen_rre_ab = 0.0\n",
    "\n",
    "    l_timestamps = []\n",
    "\n",
    "    it = 0\n",
    "    with torch.no_grad():\n",
    "        for src, target, r_ab, t_ab, _, _, _, _ in rl_loader:\n",
    "            batch_size = src.shape[0]\n",
    "\n",
    "#             print(it,'it')\n",
    "            \n",
    "            # print progress\n",
    "            print_progress=True\n",
    "            if print_progress:\n",
    "                if (((it % 100) == 0) and (it != 0)):\n",
    "                    print(it)\n",
    "                    mloss = Unseen_test_loss / it\n",
    "                    print(mloss)\n",
    "                    mloss = Unseen_euler_loss / it\n",
    "                    print(mloss)\n",
    "                    mloss = Unseen_r_mse / it\n",
    "                    print(mloss)\n",
    "                    mloss = Unseen_t_mse / it\n",
    "                    print(mloss)\n",
    "                    \n",
    "                it += 1 * batch_size\n",
    "\n",
    "            # from dataset:\n",
    "            src, target, r_ab = src.to(device), target.to(device), r_ab.to(device)\n",
    "            \n",
    "            # use augmentation generated data\n",
    "            if (0):\n",
    "\n",
    "                r_ab, t_ab, _ = get_bootstrap()\n",
    "                target = r_ab.matmul(src)\n",
    "                src, target, r_ab = src.to(device), target.to(device), r_ab.to(device)\n",
    "            \n",
    "            # use fixed modelnet40 unseen\n",
    "            else:\n",
    "                \"\"\n",
    "                src, target, r_ab, t_ab = src.to(device), target.to(device), r_ab.to(device), t_ab.to(device)\n",
    "\n",
    "            ##### Settings for SRC #####\n",
    "            # apply noise\n",
    "            target = target + torch.Tensor(target.shape).uniform_(-1 * clip, 1 * clip).to(target)\n",
    "            # scaling\n",
    "            target = scaling * target\n",
    "\n",
    "            # translate\n",
    "            translate=False\n",
    "            if translate:\n",
    "                target = target + t_ab.repeat(target.shape[0], 1, 1).permute(0, 2, 1)\n",
    "\n",
    "            if partial_easy:\n",
    "                target = partial_tensor_(target)\n",
    "\n",
    "            if sample:\n",
    "                target = sample_tensor(target)\n",
    "\n",
    "#             target = target - target.mean(dim=2, keepdims=True)\n",
    "#             src = src - src.mean(dim=2, keepdims=True)\n",
    "\n",
    "            # preprocess - eval params\n",
    "\n",
    "            src_rot = src\n",
    "            r_ab_pred = torch.eye(3, device=src.device, dtype=torch.float32).view(1, 3, 3).repeat(batch_size, 1, 1)\n",
    "            t_ab_pred = torch.zeros(3, device=src.device, dtype=torch.float32).view(1, 3)\n",
    "\n",
    "            t0 = datetime.now()\n",
    "            for ait in range(loop_iter):\n",
    "#                 print(ait,'ait')\n",
    "                \n",
    "                # Inference results\n",
    "                T_ri = net(src_rot.permute(0, 2, 1), target.permute(0, 2, 1))\n",
    "\n",
    "                r_ab_pred_ri = T_ri['est_R']\n",
    "                t_ab_pred_ri = T_ri['est_t']\n",
    "\n",
    "                # \\omega+1\n",
    "                # \\omega of current + \\omega of estimator\n",
    "                # eta*\\omega + (1-eta)*F()\n",
    "                #                     r_ab_pred_c = eta*r_ab_pred_ri + (1-eta)*r_ab_pred\n",
    "                batch_size = src.shape[0]\n",
    "\n",
    "                #                     print(r_ab_pred_ri)\n",
    "\n",
    "                if (ait > -1):\n",
    "                    # weights eta, 1-eta\n",
    "                    eta = wt[ait]\n",
    "                    eta_ = 1 - eta\n",
    "\n",
    "                    # weighing iterations\n",
    "\n",
    "                    r_ab_pred_c = eta_ * r_ab_pred.detach() + eta * r_ab_pred_ri.detach()\n",
    "                    t_ab_pred_c = eta_ * t_ab_pred.detach() + eta * t_ab_pred_ri.detach()\n",
    "\n",
    "                    # increment iterative predictions\n",
    "                    r_ab_pred = torch.matmul(r_ab_pred_c, r_ab_pred)\n",
    "\n",
    "                    t_ab_pred = t_ab_pred_c + t_ab_pred\n",
    "\n",
    "                src_rot = r_ab_pred.matmul(src) + t_ab_pred.unsqueeze(2)\n",
    "\n",
    "            # Results accum\n",
    "            l_timestamps.append((datetime.now() - t0).total_seconds())\n",
    "\n",
    "            Unseen_test_loss += F.mse_loss(r_ab, r_ab_pred) * batch_size\n",
    "\n",
    "            Unseen_test_L.append(F.mse_loss(r_ab, r_ab_pred) * batch_size)\n",
    "\n",
    "            eu_r_ab = mat2euler(r_ab)\n",
    "            eu_r_ab_pred = mat2euler(r_ab_pred)\n",
    "\n",
    "            Unseen_euler_L.append(torch.mean((eu_r_ab - eu_r_ab_pred) ** 2) * batch_size)\n",
    "\n",
    "            Unseen_euler_abs_L.append(torch.mean(torch.abs(eu_r_ab - mat2euler(r_ab_pred))) * batch_size)\n",
    "\n",
    "            Unseen_euler_loss += torch.mean((eu_r_ab - eu_r_ab_pred) ** 2) * batch_size\n",
    "\n",
    "            Unseen_euler_abs_loss += torch.mean(torch.abs(eu_r_ab - eu_r_ab_pred)) * batch_size\n",
    "\n",
    "            # Standard dcp/prnet based metrics\n",
    "            # from \n",
    "            r_mse_ab = torch.mean((r_ab - r_ab_pred) ** 2)\n",
    "            r_rmse_ab = torch.sqrt(r_mse_ab)\n",
    "            r_mae_ab = torch.mean(torch.abs(eu_r_ab - eu_r_ab_pred))\n",
    "\n",
    "            t_mse_ab = torch.mean((t_ab - t_ab_pred) ** 2)\n",
    "            t_rmse_ab = torch.sqrt(t_mse_ab)\n",
    "            t_mae_ab = torch.mean(torch.abs(t_ab - t_ab_pred))\n",
    "\n",
    "#             rre_ab = relative_rotation_err(r_ab, r_ab_pred)\n",
    "            \n",
    "#             Unseen_rre += rre_ab\n",
    "            \n",
    "            Unseen_r_mse += r_mse_ab * batch_size\n",
    "\n",
    "            Unseen_r_rmse += r_rmse_ab * batch_size\n",
    "\n",
    "            Unseen_r_mae += r_mae_ab * batch_size\n",
    "\n",
    "            Unseen_t_mse += t_mse_ab * batch_size\n",
    "\n",
    "            Unseen_t_rmse += t_rmse_ab * batch_size\n",
    "\n",
    "            Unseen_t_mae += t_mae_ab * batch_size\n",
    "            \n",
    "\n",
    "            Unseen_t_L.append(torch.mean((t_ab - t_ab_pred) ** 2) * batch_size)\n",
    "            \n",
    "            #### STD ####\n",
    "            Unseen_euler_loss_na.append(torch.mean((eu_r_ab - eu_r_ab_pred) ** 2))\n",
    "            Unseen_r_mse_na.append(F.mse_loss(r_ab, r_ab_pred))\n",
    "            Unseen_t_mse_na.append(F.mse_loss(t_ab, t_ab_pred))            \n",
    "\n",
    "    # Summarize evals\n",
    "    UnseenTest_loader = data_loader\n",
    "\n",
    "    Unseen_test_loss /= len(UnseenTest_loader.dataset)\n",
    "\n",
    "    #         Unseen_trans_loss /= len(UnseenTest_loader.dataset)\n",
    "\n",
    "    # even out\n",
    "    Unseen_euler_loss /= len(UnseenTest_loader.dataset)\n",
    "\n",
    "    Unseen_euler_abs_loss /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_r_mse /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_r_rmse /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_r_mae /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_t_mse /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_t_rmse /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_t_mae /= len(UnseenTest_loader.dataset)\n",
    "\n",
    "    Unseen_test_loss_log.append(Unseen_test_loss)\n",
    "    print('Test set: Average loss: {:.8f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        Unseen_test_loss, correct_test, len(UnseenTest_loader.dataset),\n",
    "        100. * correct_test / len(UnseenTest_loader.dataset)))\n",
    "\n",
    "    print('Trans_loss', Unseen_test_loss)\n",
    "\n",
    "    print('Trans_loss', Unseen_trans_loss)\n",
    "\n",
    "    print('euler_loss', Unseen_euler_loss)\n",
    "\n",
    "    print('euler_loss', Unseen_euler_abs_loss)\n",
    "    \n",
    "    print('r_mse', Unseen_r_mse)\n",
    "    \n",
    "    print('t_mse', Unseen_t_mse)\n",
    "\n",
    "    \n",
    "\n",
    "    total_timestamps = torch.tensor(l_timestamps).sum()\n",
    "    print('total time',total_timestamps)\n",
    "\n",
    "    d_results = {}\n",
    "    d_results['mse_R'] = Unseen_test_loss.cpu().numpy().item()\n",
    "    d_results['test_time'] = total_timestamps.cpu().numpy().item()  / len(UnseenTest_loader.dataset)\n",
    "\n",
    "    d_results['r_mse'] = Unseen_r_mse.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['r_rmse'] = Unseen_r_rmse.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['r_mae'] = Unseen_r_mae.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['t_mse'] = Unseen_t_mse.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['t_rmse'] = Unseen_t_rmse.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['t_mae'] = Unseen_t_mae.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    d_results['euler_mse'] = Unseen_euler_loss.cpu().numpy().item()\n",
    "    d_results['euler_mae'] = Unseen_euler_abs_loss.cpu().numpy().item()\n",
    "    \n",
    "#     d_results['rre'] = Unseen_rre.numpy().item()\n",
    "\n",
    "    ### print summary ###\n",
    "    print('Summary:')\n",
    "    lng = len(data_loader.dataset)\n",
    "    for k, v in d_results.items():\n",
    "        if k in ['mse_R']:\n",
    "            continue\n",
    "        print(k, v / lng)\n",
    "\n",
    "    return d_results, [Unseen_euler_loss_na,Unseen_r_mse_na,Unseen_t_mse_na]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0119b676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "\n",
    "def icp_refine(src,target,r_ab_pred,t_ab_pred, refine_threshold=0.02, max_icp=2000):\n",
    "#     if src.shape[0] > 1:\n",
    "#         print('must use 1')\n",
    "#         raise\n",
    "    assert (src.shape[0] == 1)\n",
    "    \n",
    "#     threshold=0.02\n",
    "    pred_gt=torch.zeros(4,4).to(src)\n",
    "    pred_gt[:3,:3]=r_ab_pred\n",
    "    pred_gt[:3,3]=t_ab_pred\n",
    "    pred_gt[3:,3:]=1\n",
    "\n",
    "    srcT=src[0].cpu().numpy().T\n",
    "    tarT=target[0].cpu().numpy().T    \n",
    "    trans_init=pred_gt.cpu().numpy()\n",
    "\n",
    "    srcpcd = o3d.geometry.PointCloud()\n",
    "    srcpcd.points = o3d.utility.Vector3dVector(srcT)\n",
    "\n",
    "    tgtpcd = o3d.geometry.PointCloud()\n",
    "    tgtpcd.points = o3d.utility.Vector3dVector(tarT)\n",
    "\n",
    "    # <!-- ### ICP align ### -->\n",
    "    # trans_ini=torch.diag(trans_init.shape)\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        srcpcd, tgtpcd, refine_threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=max_icp))\n",
    "    #     print(reg_p2p)\n",
    "    #     print(\"Transformation is:\")\n",
    "    #     print(reg_p2p.transformation)\n",
    "\n",
    "    T_icp=reg_p2p.transformation\n",
    "\n",
    "#     T_gt=np.zeros((4,4))\n",
    "#     T_gt[:3,:3]=r_ab\n",
    "#     T_gt[:3,3]=t_ab\n",
    "#     T_gt[3:,3:]=1\n",
    "    \n",
    "    return T_icp\n",
    "\n",
    "# Tres, trans_init, T_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81a462b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main evaluation function - With ICP refine\n",
    "def eval_rnn_with_weights_std_icp(wt=[1.0, 1.0, 1.0, 1.0], loop_iter=4, \n",
    "                                      data_loader=None, print_progress=True, refine_threshold=0.1,\n",
    "                                 max_icp=2000, icp_only=False\n",
    "                                 ):\n",
    "    if len(wt) != loop_iter:\n",
    "        print('weights do not match')\n",
    "        return\n",
    "    # By default set to modelnet40\n",
    "    if (data_loader == None):\n",
    "        data_loader = rl_loader\n",
    "        print('modelnet40', rl_loader)\n",
    "    else:\n",
    "        print('otherwise', data_loader)\n",
    "        \n",
    "    print('EVALUATE length', len(data_loader.dataset))\n",
    "\n",
    "    print('params:')\n",
    "    print('loop',loop_iter)\n",
    "    \n",
    "    Unseen_test_loss_log = []\n",
    "\n",
    "    Unseen_test_L = []\n",
    "\n",
    "    Unseen_trans_L = []\n",
    "\n",
    "    Unseen_euler_L = []\n",
    "\n",
    "    Unseen_euler_abs_L = []\n",
    "\n",
    "    Unseen_t_L = []\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    net.eval()\n",
    "    Unseen_test_loss = 0\n",
    "    Unseen_trans_loss = 0\n",
    "    Unseen_euler_loss = 0\n",
    "    Unseen_euler_abs_loss = 0\n",
    "    correct_test = 0\n",
    "    \n",
    "    ### STD\n",
    "    Unseen_euler_loss_na = []\n",
    "    Unseen_r_mse_na = []\n",
    "    Unseen_t_mse_na = []    \n",
    "\n",
    "    #### new metrics\n",
    "    Unseen_r_mse = 0.0\n",
    "    Unseen_r_rmse = 0.0\n",
    "    Unseen_r_mae = 0.0\n",
    "    Unseen_t_mse = 0.0\n",
    "    Unseen_t_rmse = 0.0\n",
    "    Unseen_t_mae = 0.0\n",
    "    \n",
    "    Unseen_rre_ab = 0.0\n",
    "\n",
    "    l_timestamps = []\n",
    "\n",
    "    it = 0\n",
    "    with torch.no_grad():\n",
    "        for src, target, r_ab, t_ab, _, _, _, _ in rl_loader:\n",
    "            batch_size = src.shape[0]\n",
    "\n",
    "#             print(it,'it')\n",
    "            \n",
    "            # print progress\n",
    "            print_progress=True\n",
    "            if print_progress:\n",
    "                if (((it % 100) == 0) and (it != 0)):\n",
    "                    print(it)\n",
    "                    mloss = Unseen_test_loss / it\n",
    "                    print(mloss)\n",
    "                    mloss = Unseen_euler_loss / it\n",
    "                    print(mloss)\n",
    "                    mloss = Unseen_r_mse / it\n",
    "                    print(mloss)\n",
    "                    mloss = Unseen_t_mse / it\n",
    "                    print(mloss)\n",
    "                    \n",
    "                it += 1 * batch_size\n",
    "\n",
    "            # from dataset:\n",
    "            src, target, r_ab = src.to(device), target.to(device), r_ab.to(device)\n",
    "            \n",
    "            # use augmentation generated data\n",
    "            if (0):\n",
    "\n",
    "                r_ab, t_ab, _ = get_bootstrap()\n",
    "                target = r_ab.matmul(src)\n",
    "                src, target, r_ab = src.to(device), target.to(device), r_ab.to(device)\n",
    "            \n",
    "            # use fixed modelnet40 unseen\n",
    "            else:\n",
    "                \"\"\n",
    "                src, target, r_ab, t_ab = src.to(device), target.to(device), r_ab.to(device), t_ab.to(device)\n",
    "\n",
    "            ##### Settings for SRC #####\n",
    "            # apply noise\n",
    "            target = target + torch.Tensor(target.shape).uniform_(-1 * clip, 1 * clip).to(target)\n",
    "            # scaling\n",
    "            target = scaling * target\n",
    "\n",
    "            # translate\n",
    "            translate=False\n",
    "            if translate:\n",
    "                target = target + t_ab.repeat(target.shape[0], 1, 1).permute(0, 2, 1)\n",
    "\n",
    "            if partial_easy:\n",
    "                target = partial_tensor_(target)\n",
    "\n",
    "            if sample:\n",
    "                target = sample_tensor(target)\n",
    "\n",
    "#             target = target - target.mean(dim=2, keepdims=True)\n",
    "#             src = src - src.mean(dim=2, keepdims=True)\n",
    "\n",
    "            # preprocess - eval params\n",
    "\n",
    "            src_rot = src\n",
    "            r_ab_pred = torch.eye(3, device=src.device, dtype=torch.float32).view(1, 3, 3).repeat(batch_size, 1, 1)\n",
    "            t_ab_pred = torch.zeros(3, device=src.device, dtype=torch.float32).view(1, 3)\n",
    "\n",
    "            t0 = datetime.now()\n",
    "            for ait in range(loop_iter):\n",
    "#                 print(ait,'ait')\n",
    "                \n",
    "                # Inference results\n",
    "                T_ri = net(src_rot.permute(0, 2, 1), target.permute(0, 2, 1))\n",
    "\n",
    "                r_ab_pred_ri = T_ri['est_R']\n",
    "                t_ab_pred_ri = T_ri['est_t']\n",
    "\n",
    "                # \\omega+1\n",
    "                # \\omega of current + \\omega of estimator\n",
    "                # eta*\\omega + (1-eta)*F()\n",
    "                #                     r_ab_pred_c = eta*r_ab_pred_ri + (1-eta)*r_ab_pred\n",
    "                batch_size = src.shape[0]\n",
    "\n",
    "                #                     print(r_ab_pred_ri)\n",
    "\n",
    "                if (ait > -1):\n",
    "                    # weights eta, 1-eta\n",
    "                    eta = wt[ait]\n",
    "                    eta_ = 1 - eta\n",
    "\n",
    "                    # weighing iterations\n",
    "\n",
    "                    r_ab_pred_c = eta_ * r_ab_pred.detach() + eta * r_ab_pred_ri.detach()\n",
    "                    t_ab_pred_c = eta_ * t_ab_pred.detach() + eta * t_ab_pred_ri.detach()\n",
    "\n",
    "                    # increment iterative predictions\n",
    "                    r_ab_pred = torch.matmul(r_ab_pred_c, r_ab_pred)\n",
    "\n",
    "                    t_ab_pred = t_ab_pred_c + t_ab_pred\n",
    "\n",
    "                src_rot = r_ab_pred.matmul(src) + t_ab_pred.unsqueeze(2)\n",
    "\n",
    "            if (icp_only):\n",
    "                # r_ab = get_boostrap()\n",
    "                r_ab9, t_ab9, _ = get_bootstrap()\n",
    "                r_ab9=r_ab9.to(device)\n",
    "                t_ab9=t_ab9.to(device)                \n",
    "                r_ab_pred_init=r_ab9.detach()\n",
    "                t_ab_pred_init=t_ab9.detach()\n",
    "            else:\n",
    "                r_ab_pred_init=r_ab_pred.detach()\n",
    "                t_ab_pred_init=t_ab_pred.detach()\n",
    "            # ICP refine\n",
    "            # t_ab_pred\n",
    "            T_icp=icp_refine(src,target,r_ab_pred_init,t_ab_pred_init,\n",
    "                             refine_threshold=refine_threshold, max_icp=max_icp)\n",
    "            T_icp=torch.from_numpy(T_icp).unsqueeze(0)\n",
    "\n",
    "            r_ab_pred=T_icp[:,:3,:3].to(device)\n",
    "            t_ab_pred=T_icp[:,:3,3].to(device)\n",
    "            r_ab = r_ab.to(device)\n",
    "            t_ab = t_ab.to(device)\n",
    "#             print(r_ab_pred.shape,src.shape,r_ab.shape,batch_size)\n",
    "#             T_icp.shape\n",
    "            \n",
    "                \n",
    "            # Results accum\n",
    "            l_timestamps.append((datetime.now() - t0).total_seconds())\n",
    "\n",
    "            Unseen_test_loss += F.mse_loss(r_ab, r_ab_pred) * batch_size\n",
    "\n",
    "            Unseen_test_L.append(F.mse_loss(r_ab, r_ab_pred) * batch_size)\n",
    "\n",
    "            eu_r_ab = mat2euler(r_ab)\n",
    "            eu_r_ab_pred = mat2euler(r_ab_pred)\n",
    "\n",
    "            Unseen_euler_L.append(torch.mean((eu_r_ab - eu_r_ab_pred) ** 2) * batch_size)\n",
    "\n",
    "            Unseen_euler_abs_L.append(torch.mean(torch.abs(eu_r_ab - mat2euler(r_ab_pred))) * batch_size)\n",
    "\n",
    "            Unseen_euler_loss += torch.mean((eu_r_ab - eu_r_ab_pred) ** 2) * batch_size\n",
    "\n",
    "            Unseen_euler_abs_loss += torch.mean(torch.abs(eu_r_ab - eu_r_ab_pred)) * batch_size\n",
    "\n",
    "            # Standard dcp/prnet based metrics\n",
    "            # from \n",
    "            r_mse_ab = torch.mean((r_ab - r_ab_pred) ** 2)\n",
    "            r_rmse_ab = torch.sqrt(r_mse_ab)\n",
    "            r_mae_ab = torch.mean(torch.abs(eu_r_ab - eu_r_ab_pred))\n",
    "\n",
    "            t_mse_ab = torch.mean((t_ab - t_ab_pred) ** 2)\n",
    "            t_rmse_ab = torch.sqrt(t_mse_ab)\n",
    "            t_mae_ab = torch.mean(torch.abs(t_ab - t_ab_pred))\n",
    "\n",
    "#             rre_ab = relative_rotation_err(r_ab, r_ab_pred)\n",
    "            \n",
    "#             Unseen_rre += rre_ab\n",
    "            \n",
    "            Unseen_r_mse += r_mse_ab * batch_size\n",
    "\n",
    "            Unseen_r_rmse += r_rmse_ab * batch_size\n",
    "\n",
    "            Unseen_r_mae += r_mae_ab * batch_size\n",
    "\n",
    "            Unseen_t_mse += t_mse_ab * batch_size\n",
    "\n",
    "            Unseen_t_rmse += t_rmse_ab * batch_size\n",
    "\n",
    "            Unseen_t_mae += t_mae_ab * batch_size\n",
    "            \n",
    "\n",
    "            Unseen_t_L.append(torch.mean((t_ab - t_ab_pred) ** 2) * batch_size)\n",
    "            \n",
    "            \n",
    "            #### STD ####\n",
    "            Unseen_euler_loss_na.append(torch.mean((eu_r_ab - eu_r_ab_pred) ** 2))\n",
    "            Unseen_r_mse_na.append(F.mse_loss(r_ab, r_ab_pred))\n",
    "            Unseen_t_mse_na.append(F.mse_loss(t_ab, t_ab_pred))             \n",
    "            \n",
    "\n",
    "    # Summarize evals\n",
    "    UnseenTest_loader = data_loader\n",
    "    print('summarize',len(data_loader))\n",
    "\n",
    "    Unseen_test_loss /= len(UnseenTest_loader.dataset)\n",
    "\n",
    "    #         Unseen_trans_loss /= len(UnseenTest_loader.dataset)\n",
    "\n",
    "    # even out\n",
    "    Unseen_euler_loss /= len(UnseenTest_loader.dataset)\n",
    "\n",
    "    Unseen_euler_abs_loss /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_r_mse /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_r_rmse /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_r_mae /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_t_mse /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_t_rmse /= len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    Unseen_t_mae /= len(UnseenTest_loader.dataset)\n",
    "\n",
    "    Unseen_test_loss_log.append(Unseen_test_loss)\n",
    "    print('Test set: Average loss: {:.8f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        Unseen_test_loss, correct_test, len(UnseenTest_loader.dataset),\n",
    "        100. * correct_test / len(UnseenTest_loader.dataset)))\n",
    "\n",
    "    print('Trans_loss', Unseen_test_loss)\n",
    "\n",
    "    print('Trans_loss', Unseen_trans_loss)\n",
    "\n",
    "    print('euler_loss', Unseen_euler_loss)\n",
    "\n",
    "    print('euler_loss', Unseen_euler_abs_loss)\n",
    "    \n",
    "    print('r_mse', Unseen_r_mse)\n",
    "    \n",
    "    print('t_mse', Unseen_t_mse)\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "    total_timestamps = torch.tensor(l_timestamps).sum()\n",
    "\n",
    "    d_results = {}\n",
    "    d_results['mse_R'] = Unseen_test_loss.cpu().numpy().item()\n",
    "    d_results['test_time'] = total_timestamps.cpu().numpy().item()  / len(UnseenTest_loader.dataset)\n",
    "\n",
    "    d_results['r_mse'] = Unseen_r_mse.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['r_rmse'] = Unseen_r_rmse.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['r_mae'] = Unseen_r_mae.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['t_mse'] = Unseen_t_mse.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['t_rmse'] = Unseen_t_rmse.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    d_results['t_mae'] = Unseen_t_mae.cpu().numpy().item() / len(UnseenTest_loader.dataset)\n",
    "    \n",
    "    d_results['euler_mse'] = Unseen_euler_loss.cpu().numpy().item()\n",
    "    d_results['euler_mae'] = Unseen_euler_abs_loss.cpu().numpy().item()\n",
    "    \n",
    "#     d_results['rre'] = Unseen_rre.numpy().item()\n",
    "\n",
    "    ### print summary ###\n",
    "    print('Summary:')\n",
    "    lng = len(data_loader.dataset)\n",
    "    for k, v in d_results.items():\n",
    "        if k in ['mse_R']:\n",
    "            continue\n",
    "        print(k, v / lng)\n",
    "\n",
    "       \n",
    "        \n",
    "    return d_results, [Unseen_euler_loss_na,Unseen_r_mse_na,Unseen_t_mse_na]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6669867",
   "metadata": {},
   "source": [
    "### Eval Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7475e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAD2DEG = 180 / (np.pi)\n",
    "DEG2RAD = (np.pi) / 180\n",
    "\n",
    "def mat2euler(r_ab):\n",
    "    return matrix_to_euler_angles(r_ab, convention='XYZ') * RAD2DEG\n",
    "\n",
    "def euler2mat(r_ab_eu):\n",
    "    return euler_angles_to_matrix(r_ab_eu * DEG2RAD, convention='XYZ')\n",
    "\n",
    "def sample_tensor(tgt):\n",
    "    leng = tgt.shape[2]\n",
    "    indice = random.sample(range(leng), leng // 2)\n",
    "    indice = torch.tensor(indice).to(device)\n",
    "    sampled_values = tgt[:, :, indice]\n",
    "    return sampled_values\n",
    "\n",
    "def partial_tensor_(t_pcd_tgt):\n",
    "    # make a cut on axis\n",
    "    t_pcd_norm_tgt = t_pcd_tgt - t_pcd_tgt.mean(dim=2, keepdim=True)\n",
    "    # t_pcd_tgt\n",
    "    sidx = t_pcd_norm_tgt.cpu()[:, 1, :] > 0.0\n",
    "\n",
    "    P_target_k = t_pcd_norm_tgt[:, :, sidx.squeeze()]\n",
    "\n",
    "    new_N = t_pcd_tgt.shape[2] - P_target_k.shape[2]\n",
    "\n",
    "    # Scale to 1.0\n",
    "    t_new = 1.0 * P_target_k\n",
    "    t_zeros = 1.0 * torch.zeros(1, 3, new_N).to(P_target_k)\n",
    "\n",
    "    t_new = torch.cat((t_new, t_zeros), axis=2)\n",
    "\n",
    "    # Translate the points to a different space - N/A\n",
    "    N_total = t_pcd_tgt.shape[2]\n",
    "\n",
    "    P_target_part = t_new\n",
    "\n",
    "    return P_target_part.to(P_target_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67054984",
   "metadata": {},
   "source": [
    "### Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a062c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 0.0\n",
    "scaling = 1.0\n",
    "partial_easy = False\n",
    "sample = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1036564",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST Seen Class ###\n",
    "data_testSeen = ModelNet40(num_points=1024, partition='test', gaussian_noise=False,\n",
    "                             unseen=False, factor=4, num_subsampled_points=1024)\n",
    "\n",
    "rl_loader = DataLoader(data_testSeen, batch_size=1, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33ed8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST UnSeen Class ###\n",
    "data_testUnseen = ModelNet40(num_points=1024, partition='test', gaussian_noise=False,\n",
    "                             unseen=True, factor=4, num_subsampled_points=1024)\n",
    "\n",
    "rl_loader = DataLoader(data_testUnseen, batch_size=1, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699c4ab",
   "metadata": {},
   "source": [
    "### Evaluate with PRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9051ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue training from the pretrained model. The model was trained to convergence based on learning3d log\n",
    "# https://github.com/vinits5/learning3d/blob/master/pretrained/exp_prnet/log\n",
    "\n",
    "device=torch.device('cuda')\n",
    "\n",
    "model = PRNet(emb_dims=args.emb_dims, num_iters=args.num_iterations, emb_nn=args.emb_nn,attention=args.pointer)\n",
    "\n",
    "if (1):\n",
    "    # !ls /workspace/program/learning3d/pretrained/exp_prnet/models\n",
    "#     dd=torch.load('/workspace/program/learning3d/pretrained/exp_prnet/models/model.99.t7',map_location=device)\n",
    "    dmp='learning3d/pretrained/exp_prnet/models/model.99.t7'\n",
    "    dd=torch.load(dmp,map_location=device)\n",
    "\n",
    "    model.load_state_dict(dd, strict=False)\n",
    "\n",
    "    \n",
    "# Net\n",
    "net=model\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8019da63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999\n",
      "learning3d/pretrained/exp_prnet/models/model.99.t7\n",
      "modelnet40 <torch.utils.data.dataloader.DataLoader object at 0x7f31149fddc0>\n",
      "EVALUATE length 2468\n",
      "params:\n",
      "loop 1\n",
      "100\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.1136, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.5485e-06, device='cuda:0', dtype=torch.float64)\n",
      "200\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.1829, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.7183e-06, device='cuda:0', dtype=torch.float64)\n",
      "300\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.1563, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.1848e-05, device='cuda:0', dtype=torch.float64)\n",
      "400\n",
      "tensor(0.0023, device='cuda:0', dtype=torch.float64)\n",
      "tensor(12.6155, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0023, device='cuda:0', dtype=torch.float64)\n",
      "tensor(9.7201e-06, device='cuda:0', dtype=torch.float64)\n",
      "500\n",
      "tensor(0.0024, device='cuda:0', dtype=torch.float64)\n",
      "tensor(12.9383, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0024, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.7539e-06, device='cuda:0', dtype=torch.float64)\n",
      "600\n",
      "tensor(0.0025, device='cuda:0', dtype=torch.float64)\n",
      "tensor(13.3033, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0025, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.0891e-05, device='cuda:0', dtype=torch.float64)\n",
      "700\n",
      "tensor(0.0024, device='cuda:0', dtype=torch.float64)\n",
      "tensor(12.7929, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0024, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.2452e-05, device='cuda:0', dtype=torch.float64)\n",
      "800\n",
      "tensor(0.0025, device='cuda:0', dtype=torch.float64)\n",
      "tensor(13.6413, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0025, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.3681e-05, device='cuda:0', dtype=torch.float64)\n",
      "900\n",
      "tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.7377, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.3399e-05, device='cuda:0', dtype=torch.float64)\n",
      "1000\n",
      "tensor(0.0027, device='cuda:0', dtype=torch.float64)\n",
      "tensor(14.8470, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0027, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.2804e-05, device='cuda:0', dtype=torch.float64)\n",
      "1100\n",
      "tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.6144, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.2711e-05, device='cuda:0', dtype=torch.float64)\n",
      "1200\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.1827, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.1893e-05, device='cuda:0', dtype=torch.float64)\n",
      "1300\n",
      "tensor(0.0030, device='cuda:0', dtype=torch.float64)\n",
      "tensor(16.0605, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0030, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.2133e-05, device='cuda:0', dtype=torch.float64)\n",
      "1400\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.4052, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.3979e-05, device='cuda:0', dtype=torch.float64)\n",
      "1500\n",
      "tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.8572, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.4144e-05, device='cuda:0', dtype=torch.float64)\n",
      "1600\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.3178, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.4972e-05, device='cuda:0', dtype=torch.float64)\n",
      "1700\n",
      "tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.8617, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.6278e-05, device='cuda:0', dtype=torch.float64)\n",
      "1800\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.2662, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.6137e-05, device='cuda:0', dtype=torch.float64)\n",
      "1900\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(14.9094, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.5713e-05, device='cuda:0', dtype=torch.float64)\n",
      "2000\n",
      "tensor(0.0027, device='cuda:0', dtype=torch.float64)\n",
      "tensor(14.4865, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0027, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.5462e-05, device='cuda:0', dtype=torch.float64)\n",
      "2100\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.0949, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.5063e-05, device='cuda:0', dtype=torch.float64)\n",
      "2200\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(15.1709, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.5406e-05, device='cuda:0', dtype=torch.float64)\n",
      "2300\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(14.9403, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0028, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.5546e-05, device='cuda:0', dtype=torch.float64)\n",
      "2400\n",
      "tensor(0.0030, device='cuda:0', dtype=torch.float64)\n",
      "tensor(16.2491, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0030, device='cuda:0', dtype=torch.float64)\n",
      "tensor(2.1108e-05, device='cuda:0', dtype=torch.float64)\n",
      "summarize 2468\n",
      "Test set: Average loss: 0.00291467, Accuracy: 0/2468 (0.00%)\n",
      "\n",
      "Trans_loss tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "Trans_loss 0\n",
      "euler_loss tensor(15.8014, device='cuda:0', dtype=torch.float64)\n",
      "euler_loss tensor(0.7612, device='cuda:0', dtype=torch.float64)\n",
      "r_mse tensor(0.0029, device='cuda:0', dtype=torch.float64)\n",
      "t_mse tensor(2.0871e-05, device='cuda:0', dtype=torch.float64)\n",
      "Summary:\n",
      "test_time 5.2070984927408655e-05\n",
      "r_mse 4.785185311002688e-10\n",
      "r_rmse 2.176950318362092e-09\n",
      "r_mae 1.2496425474409767e-07\n",
      "t_mse 3.4264430374335087e-12\n",
      "t_rmse 1.4103334808568516e-10\n",
      "t_mae 1.2210123785713875e-10\n",
      "euler_mse 0.0064025285967301586\n",
      "euler_mae 0.00030841178070843304\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "#### Seen ICPS #####\n",
    "\n",
    "### DEBUG\n",
    "# device\n",
    "# !nvidia-smi\n",
    "# device=torch.device('cuda:1')\n",
    "net=net.to(device)\n",
    "net.eval()\n",
    "2\n",
    "\n",
    "# 1. configure network configuration\n",
    "net.num_iters = 3\n",
    "\n",
    "# 2. Configure t iteration\n",
    "to = 1\n",
    "\n",
    "wt = []\n",
    "f = 0.0001\n",
    "for t in range(1, to + 1):\n",
    "    print(1 - (1 / t * f))\n",
    "    wt.append(1 - (1 / t * f))\n",
    "loop_iter = len(wt)\n",
    "\n",
    "\n",
    "print(dmp)\n",
    "# res=eval_rnn_with_weights_std_batches(wt, loop_iter)\n",
    "res, L0 =eval_rnn_with_weights_std_icp(wt, loop_iter,refine_threshold=0.2, max_icp=4000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ea70a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999\n",
      "/workspace/program/learning3d/pretrained/exp_prnet/models/model.99.t7\n",
      "modelnet40 <torch.utils.data.dataloader.DataLoader object at 0x7f2f247f27f0>\n",
      "EVALUATE length 1266\n",
      "params:\n",
      "loop 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_457/567547728.py:173: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  T_icp=torch.from_numpy(T_icp).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tensor(0.0021, device='cuda:0', dtype=torch.float64)\n",
      "tensor(10.4920, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0021, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.9909e-06, device='cuda:0', dtype=torch.float64)\n",
      "200\n",
      "tensor(0.0018, device='cuda:0', dtype=torch.float64)\n",
      "tensor(9.0661, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0018, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.2061e-05, device='cuda:0', dtype=torch.float64)\n",
      "300\n",
      "tensor(0.0018, device='cuda:0', dtype=torch.float64)\n",
      "tensor(9.3697, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0018, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.1089e-06, device='cuda:0', dtype=torch.float64)\n",
      "400\n",
      "tensor(0.0024, device='cuda:0', dtype=torch.float64)\n",
      "tensor(13.1451, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0024, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.3044e-05, device='cuda:0', dtype=torch.float64)\n",
      "500\n",
      "tensor(0.0037, device='cuda:0', dtype=torch.float64)\n",
      "tensor(22.0476, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0037, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.1261e-05, device='cuda:0', dtype=torch.float64)\n",
      "600\n",
      "tensor(0.0041, device='cuda:0', dtype=torch.float64)\n",
      "tensor(23.9565, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0041, device='cuda:0', dtype=torch.float64)\n",
      "tensor(2.7164e-05, device='cuda:0', dtype=torch.float64)\n",
      "700\n",
      "tensor(0.0037, device='cuda:0', dtype=torch.float64)\n",
      "tensor(21.3882, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0037, device='cuda:0', dtype=torch.float64)\n",
      "tensor(2.3311e-05, device='cuda:0', dtype=torch.float64)\n",
      "800\n",
      "tensor(0.0036, device='cuda:0', dtype=torch.float64)\n",
      "tensor(20.7451, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0036, device='cuda:0', dtype=torch.float64)\n",
      "tensor(2.1019e-05, device='cuda:0', dtype=torch.float64)\n",
      "900\n",
      "tensor(0.0034, device='cuda:0', dtype=torch.float64)\n",
      "tensor(19.3801, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0034, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.9868e-05, device='cuda:0', dtype=torch.float64)\n",
      "1000\n",
      "tensor(0.0031, device='cuda:0', dtype=torch.float64)\n",
      "tensor(17.7872, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0031, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.7915e-05, device='cuda:0', dtype=torch.float64)\n",
      "1100\n",
      "tensor(0.0032, device='cuda:0', dtype=torch.float64)\n",
      "tensor(18.2611, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0032, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.7112e-05, device='cuda:0', dtype=torch.float64)\n",
      "1200\n",
      "tensor(0.0031, device='cuda:0', dtype=torch.float64)\n",
      "tensor(17.4350, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0031, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.7734e-05, device='cuda:0', dtype=torch.float64)\n",
      "summarize 1266\n",
      "Test set: Average loss: 0.00295322, Accuracy: 0/1266 (0.00%)\n",
      "\n",
      "Trans_loss tensor(0.0030, device='cuda:0', dtype=torch.float64)\n",
      "Trans_loss 0\n",
      "euler_loss tensor(16.5463, device='cuda:0', dtype=torch.float64)\n",
      "euler_loss tensor(0.6640, device='cuda:0', dtype=torch.float64)\n",
      "r_mse tensor(0.0030, device='cuda:0', dtype=torch.float64)\n",
      "t_mse tensor(1.7009e-05, device='cuda:0', dtype=torch.float64)\n",
      "Summary:\n",
      "test_time 9.956086724601249e-05\n",
      "r_mse 1.8425917590212883e-09\n",
      "r_rmse 7.057296536059508e-09\n",
      "r_mae 4.1431306361239667e-07\n",
      "t_mse 1.0612440201501466e-11\n",
      "t_rmse 3.1956122119080046e-10\n",
      "t_mae 2.749231369060001e-10\n",
      "euler_mse 0.013069749187600743\n",
      "euler_mae 0.0005245203385332942\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "#### Seen ICPS #####\n",
    "\n",
    "### DEBUG\n",
    "# device\n",
    "# !nvidia-smi\n",
    "# device=torch.device('cuda:1')\n",
    "net=net.to(device)\n",
    "net.eval()\n",
    "2\n",
    "\n",
    "# 1. configure network configuration\n",
    "net.num_iters = 3\n",
    "\n",
    "# 2. Configure t iteration\n",
    "to = 1\n",
    "\n",
    "wt = []\n",
    "f = 0.0001\n",
    "for t in range(1, to + 1):\n",
    "    print(1 - (1 / t * f))\n",
    "    wt.append(1 - (1 / t * f))\n",
    "loop_iter = len(wt)\n",
    "\n",
    "\n",
    "print(dmp)\n",
    "# res=eval_rnn_with_weights_std_batches(wt, loop_iter)\n",
    "res, L0 =eval_rnn_with_weights_std_icp(wt, loop_iter,refine_threshold=0.2, max_icp=4000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d90866",
   "metadata": {},
   "source": [
    "### Evaluate with DLC-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b9c82d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rl_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "778254f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparams models\n",
    "if (1):\n",
    "    # Load hyperparams models\n",
    "    dmp='DLC_prnet_bal15N3B36_prnetTransR3.59.t7'\n",
    "    dd= torch.load(dmp)\n",
    "    a=net.load_state_dict(dd, strict=False)\n",
    "    a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "deb3c9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999\n",
      "0.99995\n",
      "0.9999666666666667\n",
      "DLC_prnet_bal15N3B36_prnetTransR3.59.t7\n",
      "modelnet40 <torch.utils.data.dataloader.DataLoader object at 0x7f31149fddc0>\n",
      "EVALUATE length 2468\n",
      "params:\n",
      "loop 3\n",
      "100\n",
      "tensor(0.0010, device='cuda:0', dtype=torch.float64)\n",
      "tensor(5.5018, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0010, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.5605e-05, device='cuda:0', dtype=torch.float64)\n",
      "200\n",
      "tensor(0.0010, device='cuda:0', dtype=torch.float64)\n",
      "tensor(5.2734, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0010, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.0782e-05, device='cuda:0', dtype=torch.float64)\n",
      "300\n",
      "tensor(0.0010, device='cuda:0', dtype=torch.float64)\n",
      "tensor(5.1349, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0010, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.6262e-05, device='cuda:0', dtype=torch.float64)\n",
      "400\n",
      "tensor(0.0014, device='cuda:0', dtype=torch.float64)\n",
      "tensor(7.8103, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0014, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.3619e-05, device='cuda:0', dtype=torch.float64)\n",
      "500\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(7.8812, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.3123e-05, device='cuda:0', dtype=torch.float64)\n",
      "600\n",
      "tensor(0.0014, device='cuda:0', dtype=torch.float64)\n",
      "tensor(7.4609, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0014, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.4520e-05, device='cuda:0', dtype=torch.float64)\n",
      "700\n",
      "tensor(0.0013, device='cuda:0', dtype=torch.float64)\n",
      "tensor(7.0631, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0013, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.6001e-05, device='cuda:0', dtype=torch.float64)\n",
      "800\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.1279, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.6548e-05, device='cuda:0', dtype=torch.float64)\n",
      "900\n",
      "tensor(0.0017, device='cuda:0', dtype=torch.float64)\n",
      "tensor(9.4523, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0017, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.8310e-05, device='cuda:0', dtype=torch.float64)\n",
      "1000\n",
      "tensor(0.0016, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.7732, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0016, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.9777e-05, device='cuda:0', dtype=torch.float64)\n",
      "1100\n",
      "tensor(0.0017, device='cuda:0', dtype=torch.float64)\n",
      "tensor(9.3657, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0017, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.8588e-05, device='cuda:0', dtype=torch.float64)\n",
      "1200\n",
      "tensor(0.0016, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.8523, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0016, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.7238e-05, device='cuda:0', dtype=torch.float64)\n",
      "1300\n",
      "tensor(0.0017, device='cuda:0', dtype=torch.float64)\n",
      "tensor(9.2958, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0017, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.7083e-05, device='cuda:0', dtype=torch.float64)\n",
      "1400\n",
      "tensor(0.0016, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.6899, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0016, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.6628e-05, device='cuda:0', dtype=torch.float64)\n",
      "1500\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.2824, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.8084e-05, device='cuda:0', dtype=torch.float64)\n",
      "1600\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.2752, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.9480e-05, device='cuda:0', dtype=torch.float64)\n",
      "1700\n",
      "tensor(0.0016, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.6067, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0016, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.9869e-05, device='cuda:0', dtype=torch.float64)\n",
      "1800\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(8.3852, device='cuda:0', dtype=torch.float64)\n",
      "tensor(0.0015, device='cuda:0', dtype=torch.float64)\n",
      "tensor(1.9527e-05, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(dmp)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# res=eval_rnn_with_weights_std_batches(wt, loop_iter)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m res, L0 \u001b[38;5;241m=\u001b[39m\u001b[43meval_rnn_with_weights_std_icp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrefine_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_icp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 129\u001b[0m, in \u001b[0;36meval_rnn_with_weights_std_icp\u001b[0;34m(wt, loop_iter, data_loader, print_progress, refine_threshold, max_icp, icp_only)\u001b[0m\n\u001b[1;32m    124\u001b[0m             t0 \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m ait \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(loop_iter):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#                 print(ait,'ait')\u001b[39;00m\n\u001b[1;32m    127\u001b[0m                 \n\u001b[1;32m    128\u001b[0m                 \u001b[38;5;66;03m# Inference results\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m                 T_ri \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_rot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m                 r_ab_pred_ri \u001b[38;5;241m=\u001b[39m T_ri[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mest_R\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m                 t_ab_pred_ri \u001b[38;5;241m=\u001b[39m T_ri[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mest_t\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/py3/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/ICCV_demo/learning3d/models/prnet.py:613\u001b[0m, in \u001b[0;36mPRNet.forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    610\u001b[0m total_scale_consensus_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iters):\n\u001b[0;32m--> 613\u001b[0m     rotation_ab_pred_i, translation_ab_pred_i, rotation_ba_pred_i, translation_ba_pred_i, feature_disparity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspam\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m     rotation_ab_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(rotation_ab_pred_i, rotation_ab_pred)\n\u001b[1;32m    616\u001b[0m     translation_ab_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(rotation_ab_pred_i, translation_ab_pred\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m translation_ab_pred_i\n",
      "File \u001b[0;32m/workspace/ICCV_demo/learning3d/models/prnet.py:569\u001b[0m, in \u001b[0;36mPRNet.spam\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspam\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    568\u001b[0m     src, tgt, src_embedding, tgt_embedding, temperature, feature_disparity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_embedding(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 569\u001b[0m     rotation_ab, translation_ab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m     rotation_ba, translation_ba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(tgt_embedding, src_embedding, tgt, src, temperature)\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rotation_ab, translation_ab, rotation_ba, translation_ba, feature_disparity\n",
      "File \u001b[0;32m/opt/conda/envs/py3/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/ICCV_demo/learning3d/models/prnet.py:235\u001b[0m, in \u001b[0;36mSVDHead.forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    232\u001b[0m         R \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m--> 235\u001b[0m             u, s, v \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m             r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(v, u\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m#             print(v.device,src.device)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######\n",
    "#### Unseen ICPS #####\n",
    "\n",
    "### DEBUG\n",
    "# device\n",
    "# !nvidia-smi\n",
    "# device=torch.device('cuda:1')\n",
    "net=net.to(device)\n",
    "net.eval()\n",
    "2\n",
    "\n",
    "# 1. configure network configuration\n",
    "net.num_iters = 3\n",
    "\n",
    "# 2. Configure t iteration\n",
    "to = 3\n",
    "\n",
    "wt = []\n",
    "f = 0.0001\n",
    "for t in range(1, to + 1):\n",
    "    print(1 - (1 / t * f))\n",
    "    wt.append(1 - (1 / t * f))\n",
    "loop_iter = len(wt)\n",
    "\n",
    "\n",
    "print(dmp)\n",
    "# res=eval_rnn_with_weights_std_batches(wt, loop_iter)\n",
    "res, L0 =eval_rnn_with_weights_std_icp(wt, loop_iter,refine_threshold=0.2, max_icp=4000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. configure network configuration\n",
    "net.num_iters = 3\n",
    "\n",
    "# 2. Configure t iteration\n",
    "to = 4\n",
    "\n",
    "wt = []\n",
    "f = 0.0001\n",
    "for t in range(1, to + 1):\n",
    "    print(1 - (1 / t * f))\n",
    "    wt.append(1 - (1 / t * f))\n",
    "loop_iter = len(wt)\n",
    "\n",
    "\n",
    "print(dmp)\n",
    "# res=eval_rnn_with_weights_std_batches(wt, loop_iter)\n",
    "res, L0 =eval_rnn_with_weights_std_icp(wt, loop_iter,refine_threshold=0.2, max_icp=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba36788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. configure network configuration\n",
    "net.num_iters = 3\n",
    "\n",
    "# 2. Configure t iteration\n",
    "to = 7\n",
    "\n",
    "wt = []\n",
    "f = 0.0001\n",
    "for t in range(1, to + 1):\n",
    "    print(1 - (1 / t * f))\n",
    "    wt.append(1 - (1 / t * f))\n",
    "loop_iter = len(wt)\n",
    "\n",
    "\n",
    "print(dmp)\n",
    "# res=eval_rnn_with_weights_std_batches(wt, loop_iter)\n",
    "res2, L1 =eval_rnn_with_weights_std_icp(wt, loop_iter,refine_threshold=0.2, max_icp=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11eba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dmp)\n",
    "# res=eval_rnn_with_weights_std_batches(wt, loop_iter)\n",
    "res3, L2 =eval_rnn_with_weights_std_batches(wt, loop_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5bbca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
